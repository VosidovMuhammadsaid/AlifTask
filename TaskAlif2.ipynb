{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOW4XFPxqFFTgbIWpMCSZzk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VosidovMuhammadsaid/AlifTask/blob/main/TaskAlif2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLWZtTAbUZNW",
        "outputId": "ea850858-0c18-4009-ee5e-6e67cd7ef085"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MQ5vynNzSo_X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import xgboost\n",
        "from sklearn.mixture import GaussianMixture as GMM\n",
        "from sklearn.model_selection import KFold\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "pd.set_option('display.max_columns', 80) \n",
        "pd.set_option('display.max_rows', 100) \n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"https://raw.githubusercontent.com/VosidovMuhammadsaid/AlifTask/main/merchants_train.csv\", sep=';')\n",
        "test = pd.read_csv(\"https://raw.githubusercontent.com/VosidovMuhammadsaid/AlifTask/main/merchants_test.csv\", sep=';')\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/VosidovMuhammadsaid/AlifTask/main/transactions.csv\")"
      ],
      "metadata": {
        "id": "BbijCXaJSygE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.set_index('merchant_id')\n",
        "test = test.set_index('merchant_id')\n",
        "data.index = data.merchant_id"
      ],
      "metadata": {
        "id": "6mjX7JgFSyeB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_time(pair):\n",
        "    x, y = pair\n",
        "    x = x.split(':')\n",
        "    y = y.split(':')\n",
        "    x = [int(i) for i in x]\n",
        "    y = [int(i) for i in y]\n",
        "    x = x[0]*3600 + x[1]*60 + x[2]\n",
        "    y = y[0]*3600 + y[1]*60 + y[2]\n",
        "    result = x - y\n",
        "    if result >= 80000:\n",
        "        result = result - 86400\n",
        "    if result <= -80000:\n",
        "        result = result + 86400\n",
        "    return abs(result)\n",
        "def preprocessing(data, train):\n",
        "    \n",
        "    data['dist'] = [tuple(i) for i in data[['latitude', 'longitude']].values]\n",
        "    y = ((data.loc[train.index][['latitude', 'longitude']] - train).apply(abs) < 0.002).min(axis=1)\n",
        "    \n",
        "    d = {}\n",
        "    for i, target in zip(data.loc[train.index]['dist'], y):\n",
        "        if i not in d:\n",
        "            d[i] = [target]\n",
        "        else:\n",
        "            d[i].append(target)\n",
        "    d2 = {}\n",
        "    for i, m, target in zip(data.loc[train.index]['dist'], data.loc[train.index].merchant_id, y):\n",
        "        if m not in d2:\n",
        "            d2[m] = {}\n",
        "            d2[m][i] = [target]\n",
        "        else:\n",
        "            if i not in d2[m]:\n",
        "                d2[m][i] = [target]\n",
        "            else:\n",
        "                d2[m][i].append(target)\n",
        "    a = []\n",
        "    b = []\n",
        "\n",
        "    for i, m in data[['dist', 'merchant_id']].values:\n",
        "        if m in train.index:\n",
        "            a.append(len(d[i]) - len(d2[m][i]))\n",
        "            b.append((np.sum(d[i]) - np.sum(d2[m][i])) / a[-1])\n",
        "        else:\n",
        "            if i not in d:\n",
        "                a.append(0)\n",
        "                b.append(np.nan)\n",
        "            else:\n",
        "                a.append(len(d[i]))\n",
        "                b.append(np.mean(d[i]))\n",
        "\n",
        "    \n",
        "    data['popularity'] = a\n",
        "    data['mean_target'] = b\n",
        "\n",
        "    min_lat = train.latitude.min() - 1\n",
        "    min_lon = train.longitude.min() - 1\n",
        "    max_lat = train.latitude.max() + 1\n",
        "    max_lon = train.longitude.max() + 1\n",
        "    \n",
        "    index = ((data.latitude > min_lat) & (data.latitude < max_lat) \\\n",
        "         &(data.longitude > min_lon) & (data.longitude < max_lon))\n",
        "    data = data[index]\n",
        "    \n",
        "    data['description'] = [tuple(i) for i in data[['merchant_id', 'latitude', 'longitude']].values]\n",
        "    data['freq3'] = data.description.map(data.description.groupby(data.description).apply(len))\n",
        "    \n",
        "    index = np.invert(data.description.duplicated())\n",
        "    data = data[index]\n",
        "    \n",
        "    dist_to_freq = data.groupby(data.dist).apply(len)\n",
        "    data['freq'] = data.dist.map(dist_to_freq)\n",
        "    data['time'] = [get_time(i) for i in data[['real_transaction_dttm', 'record_date']].values]\n",
        "    \n",
        "    return data"
      ],
      "metadata": {
        "id": "kOfQW2-XSyax"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = preprocessing(data, train)"
      ],
      "metadata": {
        "id": "WVQfUEPwVkxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = data.loc[train.index]\n",
        "data_test = data.loc[test.index]\n",
        "y = ((data_train[['latitude', 'longitude']] - train).apply(abs) < 0.002).min(axis=1)"
      ],
      "metadata": {
        "id": "0PD-a2VeVmqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prediction(data, index,  fun):\n",
        "    return data.groupby('merchant_id').apply(fun).loc[index][['latitude', 'longitude']]\n",
        "\n",
        "def get_error(p, y):\n",
        "    fire = (p.loc[y.index] - y).apply(abs) < 0.002\n",
        "    return (fire.latitude & fire.longitude).mean()\n",
        "\n",
        "def algo(x):\n",
        "    coord = x[['latitude', 'longitude']].values\n",
        "    index = np.array([True]*len(x))\n",
        "    while sum(index) > 3:\n",
        "        dist = np.mean(abs(coord - coord[index].mean(axis=0)), axis=1)\n",
        "        if sum((dist != max(dist[index])) & index) < 3:\n",
        "            break\n",
        "        index = (dist != max(dist[index])) & index\n",
        "    dist = np.mean(abs(coord - coord[index].mean(axis=0)), axis=1)\n",
        "    index = np.argmax(dist == min(dist[index]))\n",
        "    return x.iloc[index]\n",
        "\n",
        "def algo2(x):\n",
        "    model = DBSCAN()\n",
        "    coord = x[['latitude', 'longitude']].values\n",
        "    model = DBSCAN(eps=0.005, min_samples=2)\n",
        "    labels = model.fit_predict(coord)\n",
        "    clusters = sorted(np.unique(labels))\n",
        "    if len(clusters) != 1:\n",
        "        c_max = np.argmax([(labels == i).sum() for i in clusters if i != -1])\n",
        "    else:\n",
        "        c_max = clusters[0]\n",
        "    return algo(x.iloc[labels == c_max])\n",
        "\n",
        "def algo3(x):\n",
        "    lat = x.latitude.median()\n",
        "    lon = x.longitude.median()\n",
        "    fire = abs(x[['latitude', 'longitude']] - [lat, lon]).values\n",
        "    index = np.argmin(fire[:, 0]**2 + fire[:, 1]**2)\n",
        "    return x.iloc[index]"
      ],
      "metadata": {
        "id": "3Zhi9rwgSyTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = np.hstack([train.index, test.index])"
      ],
      "metadata": {
        "id": "TXRPvWleSyRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p1 = get_prediction(data[(data.mean_target != 0)], index, algo3)\n",
        "get_error(p1, train)"
      ],
      "metadata": {
        "id": "pnCHwqsxSyOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p2 = get_prediction(data[data.mean_target != 0], index, algo2)\n",
        "get_error(p2, train)"
      ],
      "metadata": {
        "id": "opbxJUqtSyLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_distribution(thr, d, some_data):\n",
        "    distribution = []\n",
        "\n",
        "    for merch, lat, lon in some_data[['merchant_id', 'latitude', 'longitude']].values:\n",
        "        dist = []\n",
        "        if merch in d:\n",
        "            tmp = (((d[merch] - [lat, lon])**2).sum(axis=1) < thr).mean()\n",
        "            distribution.append(tmp)\n",
        "        else:\n",
        "            distribution.append(np.nan)\n",
        "    return distribution"
      ],
      "metadata": {
        "id": "ZSqpHPlBSyJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gmm = GMM(n_components=3)\n",
        "gmm.fit(data[['latitude', 'longitude']])\n",
        "\n",
        "def create_X(some_data, y, is_train=True):\n",
        "    X = pd.DataFrame(index=some_data.index)\n",
        "    X['f1'] = ((some_data - p1.loc[some_data.index.unique()])[['latitude', 'longitude']].values**2).sum(axis=1)\n",
        "    X['f2'] = ((some_data - p2.loc[some_data.index.unique()])[['latitude', 'longitude']].values**2).sum(axis=1)\n",
        "    \n",
        "    X['num'] = X.groupby(X.index).apply(len)\n",
        "    X['freq'] = some_data.freq\n",
        "    \n",
        "    freq2 = [(abs(i - train.values) < 0.002).min(axis=1).sum() for i in some_data[['latitude', 'longitude']].values]\n",
        "    if is_train:\n",
        "        freq2 = freq2 - y\n",
        "    X['freq2'] = freq2\n",
        "    X['freq3'] = some_data.freq3\n",
        "    d = data.groupby(data.merchant_id).apply(lambda x: x[['latitude', 'longitude']].values).to_dict()\n",
        "    \n",
        "    X['popularity'] = some_data.popularity\n",
        "    X['mean_target'] = some_data.mean_target.fillna(0)\n",
        "    X['time'] = some_data.time\n",
        "    X['gmm'] = gmm.score(some_data[['latitude', 'longitude']].fillna(0))\n",
        "    X['distribution1'] = get_distribution(0.0001, d, some_data)\n",
        "    X['distribution2'] = get_distribution(0.00001, d, some_data)\n",
        "    \n",
        "    lat = some_data.latitude.values\n",
        "    lat2 = np.array(sells)[:,1]\n",
        "    lon = some_data.longitude.values\n",
        "    lon2 = np.array(sells)[:,0]\n",
        "    return X"
      ],
      "metadata": {
        "id": "l_T0mgjwSyGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = create_X(data_train, y)"
      ],
      "metadata": {
        "id": "N3E5Z7mLSyEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_cv(X):\n",
        "    ind_to_ind = pd.Series(range(len(X)), index=X.index)\n",
        "    index = X.index.unique()\n",
        "    n = len(index)\n",
        "    cv = KFold(n, n_folds=5, shuffle=True, random_state=241)\n",
        "    new_cv = []\n",
        "    for t, v in cv:\n",
        "        new_cv.append([ind_to_ind.loc[index[t]].values, ind_to_ind.loc[index[v]].values])\n",
        "    return new_cv"
      ],
      "metadata": {
        "id": "Qdf195nySyCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgtrain = xgboost.DMatrix(X, label=y)\n",
        "params = {'objective':'binary:logistic', \n",
        "          'eta':0.03,\n",
        "          'booster':'gbtree',\n",
        "          'max_depth':8,\n",
        "          'nthread':8, \n",
        "          'seed':0, \n",
        "          'eval_metric':'auc'}\n",
        "lalka = xgboost.cv(params=list(params.items()), \n",
        "              early_stopping_rounds=50, \n",
        "              verbose_eval=10,\n",
        "              dtrain=xgtrain,\n",
        "                folds=new_cv,\n",
        "              num_boost_round=10000)\n",
        "lalka[-1:]"
      ],
      "metadata": {
        "id": "7kJNdt5uSx_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "0.969001 227"
      ],
      "metadata": {
        "id": "4zDIgVoCTcId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = xgboost.XGBClassifier(n_estimators=220, max_depth=8, seed=241, learning_rate=0.03)\n",
        "proba = pd.Series(index=X.index)\n",
        "for t, v in new_cv:\n",
        "    model.fit(X.iloc[t], y.iloc[t])\n",
        "    proba.iloc[v] = model.predict_proba(X.iloc[v])[:,1]\n",
        "ii = proba.reset_index().groupby(proba.index).apply(lambda x: x[0].argmax()).values\n",
        "get_error(data_train.iloc[ii], train)"
      ],
      "metadata": {
        "id": "l-LloXwbTcE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = create_X(data_test, y, is_train=False)"
      ],
      "metadata": {
        "id": "pqJM3-WwTcDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y)\n",
        "proba_test = pd.Series(model.predict_proba(X_test)[:,1], index = X_test.index)"
      ],
      "metadata": {
        "id": "PbmgnXFoSx8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ii = proba_test.reset_index().groupby(proba_test.index).apply(lambda x: x[0].argmax()).values\n",
        "data_test.iloc[ii][['latitude', 'longitude']].to_csv('B2.csv', sep=';')"
      ],
      "metadata": {
        "id": "kbje2MZDSx6k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}